{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HW\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                            Message  \\\n",
       "0           0  10120                              Bugis oso near wat...   \n",
       "1           1  10121  Go until jurong point, crazy.. Available only ...   \n",
       "2           2  10122     I dunno until when... Lets go learn pilates...   \n",
       "3           3  10123  Den only weekdays got special price... Haiz......   \n",
       "4           4  10124                             Meet after lunch la...   \n",
       "\n",
       "  length country    Date  \n",
       "0     21      SG  2003/4  \n",
       "1    111      SG  2003/4  \n",
       "2     46      SG  2003/4  \n",
       "3    140      SG  2003/4  \n",
       "4     22      SG  2003/4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading file\n",
    "df = pd.read_csv(r\"C:\\Users\\HW\\Downloads\\clean_nus_sms.csv\\clean_nus_sms.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48598 entries, 0 to 48597\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  48598 non-null  int64 \n",
      " 1   id          48598 non-null  int64 \n",
      " 2   Message     48595 non-null  object\n",
      " 3   length      48598 non-null  object\n",
      " 4   country     48598 non-null  object\n",
      " 5   Date        48598 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "Message       3\n",
       "length        0\n",
       "country       0\n",
       "Date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "Message       0\n",
       "length        0\n",
       "country       0\n",
       "Date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping null values\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meet after lunch la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0                              Bugis oso near wat...\n",
       "1  Go until jurong point, crazy.. Available only ...\n",
       "2     I dunno until when... Lets go learn pilates...\n",
       "3  Den only weekdays got special price... Haiz......\n",
       "4                             Meet after lunch la..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = df[[\"Message\"]]\n",
    "message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>Date</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>bugis oso near wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>i dunno until when lets go learn pilates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>den only weekdays got special price haiz cant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>meet after lunch la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                            Message  \\\n",
       "0           0  10120                              Bugis oso near wat...   \n",
       "1           1  10121  Go until jurong point, crazy.. Available only ...   \n",
       "2           2  10122     I dunno until when... Lets go learn pilates...   \n",
       "3           3  10123  Den only weekdays got special price... Haiz......   \n",
       "4           4  10124                             Meet after lunch la...   \n",
       "\n",
       "  length country    Date                                     processed_text  \n",
       "0     21      SG  2003/4                                 bugis oso near wat  \n",
       "1    111      SG  2003/4  go until jurong point crazy available only in ...  \n",
       "2     46      SG  2003/4           i dunno until when lets go learn pilates  \n",
       "3    140      SG  2003/4  den only weekdays got special price haiz cant ...  \n",
       "4     22      SG  2003/4                                meet after lunch la  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Convert 'Message' to lowercase and remove punctuation, using .loc[]\n",
    "df.loc[:, 'processed_text'] = df['Message'].str.lower().apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#listing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>Date</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>bugis oso near wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>dunno lets go learn pilates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>den weekdays got special price haiz cant eat l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>meet lunch la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                            Message  \\\n",
       "0           0  10120                              Bugis oso near wat...   \n",
       "1           1  10121  Go until jurong point, crazy.. Available only ...   \n",
       "2           2  10122     I dunno until when... Lets go learn pilates...   \n",
       "3           3  10123  Den only weekdays got special price... Haiz......   \n",
       "4           4  10124                             Meet after lunch la...   \n",
       "\n",
       "  length country    Date                                     processed_text  \n",
       "0     21      SG  2003/4                                 bugis oso near wat  \n",
       "1    111      SG  2003/4  go jurong point crazy available bugis n great ...  \n",
       "2     46      SG  2003/4                        dunno lets go learn pilates  \n",
       "3    140      SG  2003/4  den weekdays got special price haiz cant eat l...  \n",
       "4     22      SG  2003/4                                      meet lunch la  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "#Define a function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "#Add a new column of messages after processing\n",
    "df.loc[:, 'processed_text'] = df['processed_text'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>Date</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>bugis oso near wat</td>\n",
       "      <td>[bugis, oso, near, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>dunno lets go learn pilates</td>\n",
       "      <td>[dunno, lets, go, learn, pilates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>den weekdays got special price haiz cant eat l...</td>\n",
       "      <td>[den, weekdays, got, special, price, haiz, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "      <td>meet lunch la</td>\n",
       "      <td>[meet, lunch, la]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                            Message  \\\n",
       "0           0  10120                              Bugis oso near wat...   \n",
       "1           1  10121  Go until jurong point, crazy.. Available only ...   \n",
       "2           2  10122     I dunno until when... Lets go learn pilates...   \n",
       "3           3  10123  Den only weekdays got special price... Haiz......   \n",
       "4           4  10124                             Meet after lunch la...   \n",
       "\n",
       "  length country    Date                                     processed_text  \\\n",
       "0     21      SG  2003/4                                 bugis oso near wat   \n",
       "1    111      SG  2003/4  go jurong point crazy available bugis n great ...   \n",
       "2     46      SG  2003/4                        dunno lets go learn pilates   \n",
       "3    140      SG  2003/4  den weekdays got special price haiz cant eat l...   \n",
       "4     22      SG  2003/4                                      meet lunch la   \n",
       "\n",
       "                                           tokenized  \n",
       "0                            [bugis, oso, near, wat]  \n",
       "1  [go, jurong, point, crazy, available, bugis, n...  \n",
       "2                  [dunno, lets, go, learn, pilates]  \n",
       "3  [den, weekdays, got, special, price, haiz, can...  \n",
       "4                                  [meet, lunch, la]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a new column of tokenized messages \n",
    "df[\"tokenized\"] = df[\"processed_text\"].apply(nltk.word_tokenize)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                  [bugis, oso, near, wat]\n",
      "1        [go, jurong, point, crazy, available, bugis, n...\n",
      "2                          [dunno, let, go, learn, pilate]\n",
      "3        [den, weekday, got, special, price, haiz, cant...\n",
      "4                                        [meet, lunch, la]\n",
      "                               ...                        \n",
      "48593                                         [come, noon]\n",
      "48594                                               [love]\n",
      "48595                                                [cya]\n",
      "48596                                              [guest]\n",
      "48597                           [many, many, many, people]\n",
      "Name: lemmatized, Length: 48595, dtype: object 0                                  [bugis, oso, near, wat]\n",
      "1        [go, jurong, point, crazy, available, bugis, n...\n",
      "2                        [dunno, lets, go, learn, pilates]\n",
      "3        [den, weekdays, got, special, price, haiz, can...\n",
      "4                                        [meet, lunch, la]\n",
      "                               ...                        \n",
      "48593                                         [come, noon]\n",
      "48594                                               [love]\n",
      "48595                                                [cya]\n",
      "48596                                              [guest]\n",
      "48597                           [many, many, many, people]\n",
      "Name: tokenized, Length: 48595, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizing tokens \n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "df[\"lemmatized\"] = df[\"tokenized\"].apply(lemmatize_tokens)\n",
    "print(df[\"lemmatized\"],df[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>bugis oso near wat</td>\n",
       "      <td>[bugis, oso, near, wat]</td>\n",
       "      <td>[bugis, oso, near, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>dunno lets go learn pilates</td>\n",
       "      <td>[dunno, lets, go, learn, pilates]</td>\n",
       "      <td>[dunno, let, go, learn, pilate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>den weekdays got special price haiz cant eat l...</td>\n",
       "      <td>[den, weekdays, got, special, price, haiz, can...</td>\n",
       "      <td>[den, weekday, got, special, price, haiz, cant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>meet lunch la</td>\n",
       "      <td>[meet, lunch, la]</td>\n",
       "      <td>[meet, lunch, la]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            Message length country  \\\n",
       "0  10120                              Bugis oso near wat...     21      SG   \n",
       "1  10121  Go until jurong point, crazy.. Available only ...    111      SG   \n",
       "2  10122     I dunno until when... Lets go learn pilates...     46      SG   \n",
       "3  10123  Den only weekdays got special price... Haiz......    140      SG   \n",
       "4  10124                             Meet after lunch la...     22      SG   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0                                 bugis oso near wat   \n",
       "1  go jurong point crazy available bugis n great ...   \n",
       "2                        dunno lets go learn pilates   \n",
       "3  den weekdays got special price haiz cant eat l...   \n",
       "4                                      meet lunch la   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                            [bugis, oso, near, wat]   \n",
       "1  [go, jurong, point, crazy, available, bugis, n...   \n",
       "2                  [dunno, lets, go, learn, pilates]   \n",
       "3  [den, weekdays, got, special, price, haiz, can...   \n",
       "4                                  [meet, lunch, la]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0                            [bugis, oso, near, wat]  \n",
       "1  [go, jurong, point, crazy, available, bugis, n...  \n",
       "2                    [dunno, let, go, learn, pilate]  \n",
       "3  [den, weekday, got, special, price, haiz, cant...  \n",
       "4                                  [meet, lunch, la]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"id\",\"Message\",\"length\",\"country\",\"processed_text\",\"tokenized\",\"lemmatized\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amore': 1, 'available': 1, 'buffet': 1, 'bugis': 2, 'cant': 1, 'cine': 1, 'crazy': 1, 'cut': 1, 'den': 1, 'drivin': 1, 'dunno': 1, 'e': 1, 'eat': 2, 'finish': 1, 'go': 2, 'got': 2, 'great': 1, 'haiz': 1, 'jurong': 1, 'la': 2, 'learn': 1, 'let': 1, 'liao': 1, 'lunch': 2, 'meet': 1, 'muz': 2, 'n': 1, 'nail': 1, 'near': 1, 'oso': 2, 'pilate': 1, 'point': 1, 'price': 1, 'special': 1, 'still': 1, 'wait': 1, 'wat': 4, 'weekday': 1, 'world': 1}\n"
     ]
    }
   ],
   "source": [
    "#converting messages to Bag of Words\n",
    "def text_to_bow(some_text):\n",
    "  bow_dictionary = {}\n",
    "  for token in some_text:\n",
    "    if token in bow_dictionary:\n",
    "      bow_dictionary[token] += 1\n",
    "    else:\n",
    "      bow_dictionary[token] = 1\n",
    "  return bow_dictionary\n",
    "\n",
    "flattened_tokens = sorted([token for sublist in df['lemmatized'][:5] for token in sublist])\n",
    "\n",
    "# Create the Bag-of-Words dictionary\n",
    "BOW = text_to_bow(flattened_tokens)\n",
    "print(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bugis': 0, 'oso': 1, 'near': 2, 'wat': 3, 'go': 4, 'jurong': 5, 'point': 6, 'crazy': 7, 'available': 8, 'n': 9, 'great': 10, 'world': 11, 'la': 12, 'e': 13, 'buffet': 14, 'cine': 15, 'got': 16, 'amore': 17, 'dunno': 18, 'lets': 19, 'learn': 20, 'pilates': 21, 'den': 22, 'weekdays': 23, 'special': 24, 'price': 25, 'haiz': 26, 'cant': 27, 'eat': 28, 'liao': 29, 'cut': 30, 'nails': 31, 'muz': 32, 'wait': 33, 'finish': 34, 'drivin': 35, 'lunch': 36, 'still': 37, 'meet': 38}\n"
     ]
    }
   ],
   "source": [
    "#Define function to create features dictionary\n",
    "def create_features_dictionary(documents):\n",
    "    features_dictionary = {}\n",
    "    index = 0\n",
    "    # Tokenize each document and add unique tokens to the dictionary\n",
    "    for document in documents:\n",
    "        tokens = nltk.word_tokenize(document)\n",
    "        for token in tokens:\n",
    "            if token not in features_dictionary:\n",
    "                features_dictionary[token] = index\n",
    "                index += 1\n",
    "    return features_dictionary\n",
    "\n",
    "# Print the feature dictionary for the first 5 documents\n",
    "features_dictionary = create_features_dictionary(df['processed_text'][:5])\n",
    "print(features_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#converting text to BOW vector using features_dictionary\n",
    "def text_to_bow_vector(some_text, features_dictionary):\n",
    "    bow_vector = [0] * len(features_dictionary)\n",
    "    tokens = nltk.word_tokenize(some_text)\n",
    "    for token in tokens:\n",
    "        if token in features_dictionary:  # Check if token is in dictionary\n",
    "            feature_index = features_dictionary[token]\n",
    "            bow_vector[feature_index] += 1\n",
    "    return bow_vector\n",
    "first_document = df['processed_text'][0]\n",
    "bow_vector = text_to_bow_vector(first_document, features_dictionary)\n",
    "print(bow_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three most frequent words and the number of occurrences according to Bag-of-Words:\n",
      "[('u', 9839), ('haha', 6514), ('go', 3305)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "#Define function to count words in messages\n",
    "def count_words(tokenized_texts):\n",
    "    \"\"\"Count word occurrences in a list of tokenized texts.\"\"\"\n",
    "    all_tokens = [token for tokens in tokenized_texts for token in tokens]\n",
    "    return Counter(all_tokens)\n",
    "\n",
    "# Count occurrences of words\n",
    "word_counter = count_words(df['tokenized'])\n",
    "\n",
    "# Print the three most common words\n",
    "print(\"Three most frequent words and the number of occurrences according to Bag-of-Words:\")\n",
    "print(word_counter.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 308610 stored elements and shape (48595, 38478)>\n",
      "  Coords\tValues\n",
      "  (0, 5250)\t1\n",
      "  (0, 24339)\t1\n",
      "  (0, 22375)\t1\n",
      "  (0, 36032)\t1\n",
      "  (1, 5250)\t1\n",
      "  (1, 36032)\t1\n",
      "  (1, 12813)\t1\n",
      "  (1, 17191)\t1\n",
      "  (1, 25751)\t1\n",
      "  (1, 7725)\t1\n",
      "  (1, 3384)\t1\n",
      "  (1, 13220)\t1\n",
      "  (1, 37041)\t1\n",
      "  (1, 18321)\t1\n",
      "  (1, 5244)\t1\n",
      "  (1, 6692)\t1\n",
      "  (1, 13049)\t1\n",
      "  (1, 2259)\t1\n",
      "  (2, 12813)\t1\n",
      "  (2, 9740)\t1\n",
      "  (2, 19062)\t1\n",
      "  (2, 18786)\t1\n",
      "  (2, 25462)\t1\n",
      "  (3, 24339)\t1\n",
      "  (3, 36032)\t2\n",
      "  :\t:\n",
      "  (48579, 32003)\t1\n",
      "  (48580, 36300)\t1\n",
      "  (48580, 34022)\t1\n",
      "  (48581, 5332)\t1\n",
      "  (48581, 5989)\t1\n",
      "  (48582, 35803)\t1\n",
      "  (48582, 5332)\t1\n",
      "  (48583, 9915)\t1\n",
      "  (48583, 5318)\t1\n",
      "  (48584, 12944)\t1\n",
      "  (48585, 36035)\t1\n",
      "  (48585, 18630)\t1\n",
      "  (48585, 34435)\t1\n",
      "  (48586, 28923)\t1\n",
      "  (48586, 5465)\t1\n",
      "  (48587, 14358)\t1\n",
      "  (48587, 3567)\t1\n",
      "  (48588, 33628)\t1\n",
      "  (48590, 7057)\t1\n",
      "  (48590, 22954)\t1\n",
      "  (48591, 19829)\t1\n",
      "  (48592, 7998)\t1\n",
      "  (48593, 13377)\t1\n",
      "  (48594, 20404)\t3\n",
      "  (48594, 25168)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectroizer = CountVectorizer()\n",
    "vector = vectroizer.fit_transform(df['processed_text'])\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
